{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For peer review only. A customisable version is in preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "import math,collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to remove a key from a dict\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for n choose r\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. WNGF applied to EUREGIO (macro data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EUREGIO data from https://dataportaal.pbl.nl/downloads/PBL_Euregio/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "ZPath = 'Z2010.csv' # transaction matrix\n",
    "headerPath = 'header.csv' # header with names of the sectors\n",
    "\n",
    "# load data\n",
    "myHeader = pd.read_csv(headerPath,header=None)\n",
    "cols = list(myHeader)\n",
    "myHeader['combined'] = myHeader[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "Z=np.genfromtxt(ZPath,delimiter=',')\n",
    "Z2 = np.nan_to_num(Z)\n",
    "\n",
    "# Now I collapse all the 14 sectors within the same region to have a 266 by 266 matrix.  \n",
    "DF1 = pd.DataFrame(Z2,index=myHeader[1])\n",
    "# first sum up the rows for the original matrix\n",
    "DF2 = DF1.groupby(level=0,sort=False).sum().T\n",
    "# second sum up the columns for the original matrix\n",
    "DF2.index = myHeader[1]\n",
    "DF3 = DF2.groupby(level=0,sort=False).sum().T\n",
    "\n",
    "nodeNames = list(DF3.index)\n",
    "\n",
    "# count the number of regions in each country\n",
    "ctryNames = [x[:2] for x in nodeNames]\n",
    "ctryCount = {x:ctryNames.count(x) for x in ctryNames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 define normalisation denominators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinator normalisation denominator\n",
    "def normCo(node,ctryCount):\n",
    "    ctry = node[:2]\n",
    "    n = ctryCount[ctry]\n",
    "    if n>2:\n",
    "        m = nCr(n-1,2)*2\n",
    "    else:\n",
    "        m = 1\n",
    "    return m\n",
    "\n",
    "# gatekeeper and representative normalisation denominator\n",
    "def normGaRe(node,ctryCount):\n",
    "    ctry = node[:2]\n",
    "    n = ctryCount[ctry]\n",
    "    newCount = removekey(ctryCount,ctry)\n",
    "    if n>1:\n",
    "        m = 0\n",
    "        for key in newCount:\n",
    "            m += newCount[key]*(n-1)\n",
    "    else:\n",
    "        m = 1\n",
    "    return m\n",
    "\n",
    "# itinerant normalisation denominator\n",
    "def normIt(node,ctryCount):\n",
    "    ctry = node[:2]\n",
    "    n = ctryCount[ctry]\n",
    "    newCount = removekey(ctryCount,ctry)\n",
    "    m = 0\n",
    "    for key in newCount:\n",
    "        temp = newCount[key]\n",
    "        if temp > 1:\n",
    "            m += nCr(temp,2)*2\n",
    "    return m\n",
    "\n",
    "# liaison normalisation denominator\n",
    "def normLi(node,ctryCount):\n",
    "    ctry = node[:2]\n",
    "    n = ctryCount[ctry]\n",
    "    newCount = removekey(ctryCount,ctry)\n",
    "    m = 0\n",
    "    for key in newCount:\n",
    "        v1 = newCount[key]\n",
    "        tempCount = removekey(newCount,key)\n",
    "        for ind in tempCount:\n",
    "            v2 = tempCount[ind]\n",
    "            m += v1*v2\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "# Note that I have removed the self-loops. \n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in nodeNames:\n",
    "    for j in nodeNames:\n",
    "        if i != j:\n",
    "            G.add_edge(i,j,weight=DF3.loc[i,j])\n",
    "            \n",
    "for node in G.nodes:\n",
    "    G.nodes[node]['country'] = node[:2] # the first two letters are distinct across countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. WNGF applied to R&D information flow (micro data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R&D information flow data from https://toreopsahl.com/datasets/#Cross_Parker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "MatrixPath = 'Cross_Parker-Manufacturing_info (differentiated in terms of advice).xlsx'\n",
    "attributePath = 'Cross_Parker-Manufacturing_ATTR.xlsx'\n",
    "\n",
    "# load data\n",
    "matrix = pd.read_excel(MatrixPath, header=0, index_col=0)\n",
    "attribute = pd.read_excel(attributePath, header=0, index_col=0)\n",
    "\n",
    "nodeNames = list(attribute.index)\n",
    "\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (attribute['location'] == 1),\n",
    "    (attribute['location'] == 2),\n",
    "    (attribute['location'] == 3),\n",
    "    (attribute['location'] == 4)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['Paris', 'Frankfurt', ' Warsaw', 'Geneva']\n",
    "attribute['city'] = np.select(conditions, values)\n",
    "\n",
    "# count the number of people in each location\n",
    "Count = dict(collections.Counter(attribute.city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 define normalisation denominators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinator normalisation denominator\n",
    "def normCo(node,Count):\n",
    "    city = attribute.loc[node].city \n",
    "    n = Count[city]\n",
    "    if n>2:\n",
    "        m = nCr(n-1,2)*2\n",
    "    else:\n",
    "        m = 1\n",
    "    return m\n",
    "\n",
    "# gatekeeper and representative normalisation denominator\n",
    "def normGaRe(node,Count):\n",
    "    city = attribute.loc[node].city\n",
    "    n = Count[city]\n",
    "    newCount = removekey(Count,city)\n",
    "    if n>1:\n",
    "        m = 0\n",
    "        for key in newCount:\n",
    "            m += newCount[key]*(n-1)\n",
    "    else:\n",
    "        m = 1\n",
    "    return m\n",
    "\n",
    "# itinerant normalisation denominator\n",
    "def normIt(node,Count):\n",
    "    city = attribute.loc[node].city\n",
    "    n = Count[city]\n",
    "    newCount = removekey(Count,city)\n",
    "    m = 0\n",
    "    for key in newCount:\n",
    "        temp = newCount[key]\n",
    "        if temp > 1:\n",
    "            m += nCr(temp,2)*2\n",
    "    return m\n",
    "\n",
    "# liaison normalisation denominator\n",
    "def normLi(node,Count):\n",
    "    city = attribute.loc[node].city\n",
    "    n = Count[city]\n",
    "    newCount = removekey(Count,city)\n",
    "    m = 0\n",
    "    for key in newCount:\n",
    "        v1 = newCount[key]\n",
    "        tempCount = removekey(newCount,key)\n",
    "        for ind in tempCount:\n",
    "            v2 = tempCount[ind]\n",
    "            m += v1*v2\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in nodeNames:\n",
    "    for j in nodeNames:\n",
    "        if i != j:\n",
    "            G.add_edge(i,j,weight=matrix.loc[i,j])\n",
    "            \n",
    "for node in G.nodes:\n",
    "    G.nodes[node]['city'] = attribute.loc[node].city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. WNGF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I am going to calculate the number of occurances for shortest path each type of the brokerage. \n",
    "\n",
    "GF = {}\n",
    "for node in G.nodes:\n",
    "    temp = {'coordinator':0, 'itinerant':0, 'gatekeeper':0, 'representative':0, 'liaison':0, 'total':0,\n",
    "           'coPairs':[], 'itPairs':[], 'gaPairs':[], 'rePairs':[], 'liPairs':[], 'toPairs':[]}\n",
    "    for up in G.predecessors(node):\n",
    "        for down in G.successors(node):\n",
    "            if up != down:\n",
    "                w_updown = G[up][down]['weight']\n",
    "                w_upn = G[up][node]['weight']\n",
    "                w_ndown = G[node][down]['weight']\n",
    "                if (w_updown==0 and w_upn>0 and w_ndown>0) or (w_updown>0 and w_upn>0 and w_ndown>0 and 1/w_updown>1/w_upn+1/w_ndown):\n",
    "                    if G.nodes[up]['city']==G.nodes[node]['city']==G.nodes[down]['city']:\n",
    "                        temp['coordinator'] += 1\n",
    "                        temp['coPairs'].append([up,down])\n",
    "                        temp['total'] += 1\n",
    "                        temp['toPairs'].append([up,down])\n",
    "                    elif G.nodes[up]['city']==G.nodes[down]['city']!=G.nodes[node]['city']:\n",
    "                        temp['itinerant'] += 1\n",
    "                        temp['itPairs'].append([up,down])\n",
    "                        temp['total'] += 1\n",
    "                        temp['toPairs'].append([up,down])\n",
    "                    elif G.nodes[up]['city']!=G.nodes[down]['city']==G.nodes[node]['city']:\n",
    "                        temp['gatekeeper'] += 1\n",
    "                        temp['gaPairs'].append([up,down])\n",
    "                        temp['total'] += 1\n",
    "                        temp['toPairs'].append([up,down])\n",
    "                    elif G.nodes[up]['city']==G.nodes[node]['city']!=G.nodes[down]['city']:\n",
    "                        temp['representative'] += 1\n",
    "                        temp['rePairs'].append([up,down])\n",
    "                        temp['total'] += 1\n",
    "                        temp['toPairs'].append([up,down])\n",
    "                    elif G.nodes[up]['city']!=G.nodes[node]['city']!=G.nodes[down]['city'] and G.nodes[up]['city']!=G.nodes[down]['city']:\n",
    "                        temp['liaison'] += 1\n",
    "                        temp['liPairs'].append([up,down])\n",
    "                        temp['total'] += 1\n",
    "                        temp['toPairs'].append([up,down])\n",
    "\n",
    "    \n",
    "    # Note that this time all the five roles frequencies are normalised. \n",
    "    temp['coordinator'] = temp['coordinator']/normCo(node,Count)\n",
    "    temp['itinerant'] = temp['itinerant']/normIt(node,Count)\n",
    "    temp['gatekeeper'] = temp['gatekeeper']/normGaRe(node,Count)\n",
    "    temp['representative'] = temp['representative']/normGaRe(node,Count)\n",
    "    temp['liaison'] = temp['liaison']/normLi(node,Count)\n",
    "    GF[node]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I reorganise the results\n",
    "\n",
    "coRank = []\n",
    "itRank = []\n",
    "gaRank = []\n",
    "reRank = []\n",
    "liRank = []\n",
    "toRank = []\n",
    "for node in nodeNames:\n",
    "    coRank.append({'node':node, 'coordinator':GF[node]['coordinator']})\n",
    "    itRank.append({'node':node, 'itinerant':GF[node]['itinerant']})\n",
    "    gaRank.append({'node':node, 'gatekeeper':GF[node]['gatekeeper']})\n",
    "    reRank.append({'node':node, 'representative':GF[node]['representative']})\n",
    "    liRank.append({'node':node, 'liaison':GF[node]['liaison']})\n",
    "    toRank.append({'node':node, 'total':GF[node]['total']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn them into DataFrame\n",
    "\n",
    "coRankDF = pd.DataFrame(coRank)\n",
    "itRankDF = pd.DataFrame(itRank)\n",
    "gaRankDF = pd.DataFrame(gaRank)\n",
    "reRankDF = pd.DataFrame(reRank)\n",
    "liRankDF = pd.DataFrame(liRank)\n",
    "toRankDF = pd.DataFrame(toRank)\n",
    "gf_freq = pd.concat([coRankDF, itRankDF.itinerant, gaRankDF.gatekeeper, reRankDF.representative,\n",
    "           liRankDF.liaison, toRankDF.total], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different roles, for example, gatekeeper\n",
    "# Other types can be sorted by changing the argument \"by\"\n",
    "\n",
    "gf_freq.sort_values(by='gatekeeper', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
